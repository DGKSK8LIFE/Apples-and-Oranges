{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "`validation_split` is only supported for Tensors or NumPy arrays, found: (array([[[[0.12156863, 0.15294118, 0.13333333],\n         [0.20392157, 0.41568627, 0.4       ],\n         [0.86666667, 0.98039216, 0.97254902],\n         ...,\n         [0.00784314, 0.69411765, 0.99607843],\n         [0.05098039, 0.68627451, 0.99215686],\n         [0.31764706, 0.71764706, 0.99607843]],\n\n        [[0.01176471, 0.30980392, 0.26666667],\n         [0.20392157, 0.33333333, 0.39607843],\n         [0.49411765, 0.92941176, 0.98823529],\n         ...,\n         [0.08235294, 0.69803922, 0.99215686],\n         [0.10980392, 0.60784314, 0.97254902],\n         [0.01568627, 0.56470588, 0.99215686]],\n\n        [[0.25882353, 0.17647059, 0.18431373],\n         [0.5372549 , 0.85882353, 0.93333333],\n         [0.70588235, 0.94509804, 0.98823529],\n         ...,\n         [0.06666667, 0.68235294, 0.99215686],\n         [0.05490196, 0.65098039, 0.99215686],\n         [0.00784314, 0.59607843, 0.98823529]],\n\n        ...,\n\n        [[0.56470588, 0.65490196, 0.81960784],\n         [0.55686275, 0.61176471, 0.77647059],\n         [0.60392157, 0.69019608, 0.83529412],\n         ...,\n         [0.07058824, 0.0745098 , 0.11764706],\n         [0.06666667, 0.07058824, 0.10980392],\n         [0.0627451 , 0.06666667, 0.10588235]],\n\n        [[0.62745098, 0.69803922, 0.82352941],\n         [0.6       , 0.64313725, 0.81960784],\n         [0.58431373, 0.6627451 , 0.82745098],\n         ...,\n         [0.0627451 , 0.06666667, 0.10588235],\n         [0.07058824, 0.0745098 , 0.11372549],\n         [0.07058824, 0.0745098 , 0.11372549]],\n\n        [[0.60392157, 0.67843137, 0.82352941],\n         [0.56862745, 0.63529412, 0.80392157],\n         [0.51764706, 0.60392157, 0.79607843],\n         ...,\n         [0.0745098 , 0.07843137, 0.11764706],\n         [0.0745098 , 0.0745098 , 0.11764706],\n         [0.08235294, 0.08627451, 0.1254902 ]]],\n\n\n       [[[0.70196078, 0.60392157, 0.54117647],\n         [0.70980392, 0.61568627, 0.54509804],\n         [0.65882353, 0.59215686, 0.54117647],\n         ...,\n         [0.07058824, 0.21176471, 0.43921569],\n         [0.05882353, 0.18431373, 0.40784314],\n         [0.07058824, 0.18039216, 0.41176471]],\n\n        [[0.69803922, 0.60392157, 0.54117647],\n         [0.70588235, 0.61568627, 0.54901961],\n         [0.41176471, 0.41568627, 0.47058824],\n         ...,\n         [0.07843137, 0.19607843, 0.45882353],\n         [0.14901961, 0.23529412, 0.43137255],\n         [0.19607843, 0.26666667, 0.42745098]],\n\n        [[0.70588235, 0.60784314, 0.54509804],\n         [0.58823529, 0.54117647, 0.52156863],\n         [0.29803922, 0.35294118, 0.44705882],\n         ...,\n         [0.09411765, 0.21568627, 0.49019608],\n         [0.0627451 , 0.19215686, 0.43137255],\n         [0.03921569, 0.16862745, 0.41568627]],\n\n        ...,\n\n        [[0.11764706, 0.2627451 , 0.49019608],\n         [0.10980392, 0.25490196, 0.49019608],\n         [0.08627451, 0.23529412, 0.47843137],\n         ...,\n         [0.25882353, 0.39215686, 0.56078431],\n         [0.37254902, 0.43137255, 0.56470588],\n         [0.30980392, 0.40392157, 0.53333333]],\n\n        [[0.10196078, 0.23529412, 0.47058824],\n         [0.07843137, 0.23137255, 0.46666667],\n         [0.10196078, 0.25490196, 0.48627451],\n         ...,\n         [0.50980392, 0.48235294, 0.57647059],\n         [0.03529412, 0.27843137, 0.48627451],\n         [0.02745098, 0.28627451, 0.49411765]],\n\n        [[0.11764706, 0.24705882, 0.46666667],\n         [0.09019608, 0.24313725, 0.48235294],\n         [0.1254902 , 0.25098039, 0.49019608],\n         ...,\n         [0.05098039, 0.25882353, 0.51372549],\n         [0.21568627, 0.35294118, 0.5254902 ],\n         [0.54117647, 0.45882353, 0.58039216]]],\n\n\n       [[[0.04705882, 0.40392157, 0.81176471],\n         [0.03529412, 0.38431373, 0.81568627],\n         [0.06666667, 0.41960784, 0.84705882],\n         ...,\n         [0.6       , 0.32941176, 0.25490196],\n         [0.2       , 0.24705882, 0.34117647],\n         [0.25098039, 0.38823529, 0.52156863]],\n\n        [[0.03921569, 0.34509804, 0.78431373],\n         [0.03137255, 0.3372549 , 0.79215686],\n         [0.05882353, 0.37647059, 0.82745098],\n         ...,\n         [0.37647059, 0.19607843, 0.18431373],\n         [0.17647059, 0.27058824, 0.40392157],\n         [0.25882353, 0.38823529, 0.54117647]],\n\n        [[0.03529412, 0.29803922, 0.76470588],\n         [0.02352941, 0.28627451, 0.7372549 ],\n         [0.07843137, 0.26666667, 0.75686275],\n         ...,\n         [0.15686275, 0.12941176, 0.14117647],\n         [0.21960784, 0.34901961, 0.48627451],\n         [0.24313725, 0.38039216, 0.5372549 ]],\n\n        ...,\n\n        [[0.45490196, 0.56078431, 0.69019608],\n         [0.39215686, 0.50196078, 0.63921569],\n         [0.41960784, 0.55686275, 0.69019608],\n         ...,\n         [0.04705882, 0.45882353, 0.85882353],\n         [0.84705882, 0.90980392, 0.94901961],\n         [0.04313725, 0.49803922, 0.83921569]],\n\n        [[0.58823529, 0.62352941, 0.67058824],\n         [0.47058824, 0.54901961, 0.67058824],\n         [0.42352941, 0.54901961, 0.67058824],\n         ...,\n         [0.04705882, 0.4       , 0.79215686],\n         [0.03137255, 0.43529412, 0.79607843],\n         [0.05490196, 0.45882353, 0.82352941]],\n\n        [[0.71764706, 0.4       , 0.29411765],\n         [0.52156863, 0.23921569, 0.24313725],\n         [0.45490196, 0.55294118, 0.63137255],\n         ...,\n         [0.06666667, 0.39607843, 0.73333333],\n         [0.12941176, 0.39607843, 0.74509804],\n         [0.04705882, 0.37647059, 0.75294118]]],\n\n\n       ...,\n\n\n       [[[0.00784314, 0.00784314, 0.07058824],\n         [0.01568627, 0.01568627, 0.07843137],\n         [0.02745098, 0.00784314, 0.09019608],\n         ...,\n         [0.        , 0.        , 0.04705882],\n         [0.01176471, 0.01176471, 0.0745098 ],\n         [0.01176471, 0.01960784, 0.0627451 ]],\n\n        [[0.00392157, 0.00784314, 0.06666667],\n         [0.01176471, 0.01568627, 0.07058824],\n         [0.03921569, 0.15686275, 0.69019608],\n         ...,\n         [0.00392157, 0.00392157, 0.05098039],\n         [0.01568627, 0.01960784, 0.0627451 ],\n         [0.01568627, 0.01960784, 0.0745098 ]],\n\n        [[0.00392157, 0.00392157, 0.07843137],\n         [0.02352941, 0.01960784, 0.12156863],\n         [0.09411765, 0.39215686, 0.94901961],\n         ...,\n         [0.01568627, 0.02352941, 0.07058824],\n         [0.01176471, 0.01960784, 0.06666667],\n         [0.01176471, 0.01568627, 0.0745098 ]],\n\n        ...,\n\n        [[0.03529412, 0.02352941, 0.38039216],\n         [0.01960784, 0.01568627, 0.4       ],\n         [0.01568627, 0.02745098, 0.35686275],\n         ...,\n         [0.01960784, 0.03137255, 0.10196078],\n         [0.00784314, 0.03529412, 0.09803922],\n         [0.00784314, 0.03921569, 0.10588235]],\n\n        [[0.01568627, 0.01568627, 0.38039216],\n         [0.01176471, 0.02352941, 0.27843137],\n         [0.01960784, 0.02745098, 0.21568627],\n         ...,\n         [0.01176471, 0.04313725, 0.10980392],\n         [0.01176471, 0.03921569, 0.10196078],\n         [0.01176471, 0.04705882, 0.10196078]],\n\n        [[0.01176471, 0.03921569, 0.1372549 ],\n         [0.01176471, 0.03921569, 0.14901961],\n         [0.01176471, 0.03921569, 0.1372549 ],\n         ...,\n         [0.00784314, 0.03921569, 0.10588235],\n         [0.01176471, 0.03921569, 0.09411765],\n         [0.01176471, 0.04705882, 0.10196078]]],\n\n\n       [[[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 0.99607843],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]],\n\n        ...,\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]]],\n\n\n       [[[0.13333333, 0.18431373, 0.19215686],\n         [0.17647059, 0.23921569, 0.25098039],\n         [0.27843137, 0.34901961, 0.38823529],\n         ...,\n         [0.10980392, 0.11372549, 0.09803922],\n         [0.08627451, 0.09411765, 0.07058824],\n         [0.07843137, 0.08627451, 0.0627451 ]],\n\n        [[0.35686275, 0.42352941, 0.48627451],\n         [0.45098039, 0.52941176, 0.60784314],\n         [0.5254902 , 0.58431373, 0.68627451],\n         ...,\n         [0.11764706, 0.12156863, 0.10980392],\n         [0.08235294, 0.08627451, 0.07058824],\n         [0.08235294, 0.08627451, 0.07058824]],\n\n        [[0.54901961, 0.60392157, 0.71764706],\n         [0.57254902, 0.64313725, 0.76078431],\n         [0.55686275, 0.65098039, 0.76862745],\n         ...,\n         [0.11372549, 0.11764706, 0.10980392],\n         [0.08235294, 0.08627451, 0.0745098 ],\n         [0.08627451, 0.09019608, 0.0745098 ]],\n\n        ...,\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.03529412, 0.05098039, 0.04313725],\n         [0.03921569, 0.05098039, 0.04313725],\n         [0.03921569, 0.05882353, 0.05490196]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.00392157, 0.00392157, 0.00392157],\n         [0.00392157, 0.00392157, 0.00392157],\n         ...,\n         [0.05098039, 0.06666667, 0.05882353],\n         [0.03921569, 0.04705882, 0.03921569],\n         [0.03921569, 0.05882353, 0.05098039]],\n\n        [[0.00784314, 0.00784314, 0.00784314],\n         [0.00784314, 0.00784314, 0.00784314],\n         [0.01176471, 0.01176471, 0.01176471],\n         ...,\n         [0.03529412, 0.05490196, 0.04705882],\n         [0.03921569, 0.05098039, 0.03921569],\n         [0.05098039, 0.07058824, 0.0627451 ]]]]), [1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1], None)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7729ec2f54ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    793\u001b[0m       \u001b[0;31m# `Tensor` and `NumPy` input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       (x, y, sample_weight), validation_data = (\n\u001b[0;32m--> 795\u001b[0;31m           data_adapter.train_validation_split((x, y, sample_weight),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                               \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                               shuffle=False))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   1307\u001b[0m   \u001b[0mflat_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_can_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1310\u001b[0m         \u001b[0;34m\"`validation_split` is only supported for Tensors or NumPy \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \"arrays, found: {}\".format(arrays))\n",
      "\u001b[0;31mValueError\u001b[0m: `validation_split` is only supported for Tensors or NumPy arrays, found: (array([[[[0.12156863, 0.15294118, 0.13333333],\n         [0.20392157, 0.41568627, 0.4       ],\n         [0.86666667, 0.98039216, 0.97254902],\n         ...,\n         [0.00784314, 0.69411765, 0.99607843],\n         [0.05098039, 0.68627451, 0.99215686],\n         [0.31764706, 0.71764706, 0.99607843]],\n\n        [[0.01176471, 0.30980392, 0.26666667],\n         [0.20392157, 0.33333333, 0.39607843],\n         [0.49411765, 0.92941176, 0.98823529],\n         ...,\n         [0.08235294, 0.69803922, 0.99215686],\n         [0.10980392, 0.60784314, 0.97254902],\n         [0.01568627, 0.56470588, 0.99215686]],\n\n        [[0.25882353, 0.17647059, 0.18431373],\n         [0.5372549 , 0.85882353, 0.93333333],\n         [0.70588235, 0.94509804, 0.98823529],\n         ...,\n         [0.06666667, 0.68235294, 0.99215686],\n         [0.05490196, 0.65098039, 0.99215686],\n         [0.00784314, 0.59607843, 0.98823529]],\n\n        ...,\n\n        [[0.56470588, 0.65490196, 0.81960784],\n         [0.55686275, 0.61176471, 0.77647059],\n         [0.60392157, 0.69019608, 0.83529412],\n         ...,\n         [0.07058824, 0.0745098 , 0.11764706],\n         [0.06666667, 0.07058824, 0.10980392],\n         [0.0627451 , 0.06666667, 0.10588235]],\n\n        [[0.62745098, 0.69803922, 0.82352941],\n         [0.6       , 0.64313725, 0.81960784],\n         [0.58431373, 0.6627451 , 0.82745098],\n         ...,\n         [0.0627451 , 0.06666667, 0.10588235],\n         [0.07058824, 0.0745098 , 0.11372549],\n         [0.07058824, 0.0745098 , 0.11372549]],\n\n        [[0.60392157, 0.67843137, 0.82352941],\n         [0.56862745, 0.63529412, 0.80392157],\n         [0.51764706, 0.60392157, 0.79607843],\n         ...,\n         [0.0745098 , 0.07843137, 0.11764706],\n         [0.0745098 , 0.0745098 , 0.11764706],\n         [0.08235294, 0.08627451, 0.1254902 ]]],\n\n\n       [[[0.70196078, 0.60392157, 0.54117647],\n         [0.70980392, 0.61568627, 0.54509804],\n         [0.65882353, 0.59215686, 0.54117647],\n         ...,\n         [0.07058824, 0.21176471, 0.43921569],\n         [0.05882353, 0.18431373, 0.40784314],\n         [0.07058824, 0.18039216, 0.41176471]],\n\n        [[0.69803922, 0.60392157, 0.54117647],\n         [0.70588235, 0.61568627, 0.54901961],\n         [0.41176471, 0.41568627, 0.47058824],\n         ...,\n         [0.07843137, 0.19607843, 0.45882353],\n         [0.14901961, 0.23529412, 0.43137255],\n         [0.19607843, 0.26666667, 0.42745098]],\n\n        [[0.70588235, 0.60784314, 0.54509804],\n         [0.58823529, 0.54117647, 0.52156863],\n         [0.29803922, 0.35294118, 0.44705882],\n         ...,\n         [0.09411765, 0.21568627, 0.49019608],\n         [0.0627451 , 0.19215686, 0.43137255],\n         [0.03921569, 0.16862745, 0.41568627]],\n\n        ...,\n\n        [[0.11764706, 0.2627451 , 0.49019608],\n         [0.10980392, 0.25490196, 0.49019608],\n         [0.08627451, 0.23529412, 0.47843137],\n         ...,\n         [0.25882353, 0.39215686, 0.56078431],\n         [0.37254902, 0.43137255, 0.56470588],\n         [0.30980392, 0.40392157, 0.53333333]],\n\n        [[0.10196078, 0.23529412, 0.47058824],\n         [0.07843137, 0.23137255, 0.46666667],\n         [0.10196078, 0.25490196, 0.48627451],\n         ...,\n         [0.50980392, 0.48235294, 0.57647059],\n         [0.03529412, 0.27843137, 0.48627451],\n         [0.02745098, 0.28627451, 0.49411765]],\n\n        [[0.11764706, 0.24705882, 0.46666667],\n         [0.09019608, 0.24313725, 0.48235294],\n         [0.1254902 , 0.25098039, 0.49019608],\n         ...,\n         [0.05098039, 0.25882353, 0.51372549],\n         [0.21568627, 0.35294118, 0.5254902 ],\n         [0.54117647, 0.45882353, 0.58039216]]],\n\n\n       [[[0.04705882, 0.40392157, 0.81176471],\n         [0.03529412, 0.38431373, 0.81568627],\n         [0.06666667, 0.41960784, 0.84705882],\n         ...,\n         [0.6       , 0.32941176, 0.25490196],\n         [0.2       , 0.24705882, 0.34117647],\n         [0.25098039, 0.38823529, 0.52156863]],\n\n        [[0.03921569, 0.34509804, 0.78431373],\n         [0.03137255, 0.3372549 , 0.79215686],\n         [0.05882353, 0.37647059, 0.82745098],\n         ...,\n         [0.37647059, 0.19607843, 0.18431373],\n         [0.17647059, 0.27058824, 0.40392157],\n         [0.25882353, 0.38823529, 0.54117647]],\n\n        [[0.03529412, 0.29803922, 0.76470588],\n         [0.02352941, 0.28627451, 0.7372549 ],\n         [0.07843137, 0.26666667, 0.75686275],\n         ...,\n         [0.15686275, 0.12941176, 0.14117647],\n         [0.21960784, 0.34901961, 0.48627451],\n         [0.24313725, 0.38039216, 0.5372549 ]],\n\n        ...,\n\n        [[0.45490196, 0.56078431, 0.69019608],\n         [0.39215686, 0.50196078, 0.63921569],\n         [0.41960784, 0.55686275, 0.69019608],\n         ...,\n         [0.04705882, 0.45882353, 0.85882353],\n         [0.84705882, 0.90980392, 0.94901961],\n         [0.04313725, 0.49803922, 0.83921569]],\n\n        [[0.58823529, 0.62352941, 0.67058824],\n         [0.47058824, 0.54901961, 0.67058824],\n         [0.42352941, 0.54901961, 0.67058824],\n         ...,\n         [0.04705882, 0.4       , 0.79215686],\n         [0.03137255, 0.43529412, 0.79607843],\n         [0.05490196, 0.45882353, 0.82352941]],\n\n        [[0.71764706, 0.4       , 0.29411765],\n         [0.52156863, 0.23921569, 0.24313725],\n         [0.45490196, 0.55294118, 0.63137255],\n         ...,\n         [0.06666667, 0.39607843, 0.73333333],\n         [0.12941176, 0.39607843, 0.74509804],\n         [0.04705882, 0.37647059, 0.75294118]]],\n\n\n       ...,\n\n\n       [[[0.00784314, 0.00784314, 0.07058824],\n         [0.01568627, 0.01568627, 0.07843137],\n         [0.02745098, 0.00784314, 0.09019608],\n         ...,\n         [0.        , 0.        , 0.04705882],\n         [0.01176471, 0.01176471, 0.0745098 ],\n         [0.01176471, 0.01960784, 0.0627451 ]],\n\n        [[0.00392157, 0.00784314, 0.06666667],\n         [0.01176471, 0.01568627, 0.07058824],\n         [0.03921569, 0.15686275, 0.69019608],\n         ...,\n         [0.00392157, 0.00392157, 0.05098039],\n         [0.01568627, 0.01960784, 0.0627451 ],\n         [0.01568627, 0.01960784, 0.0745098 ]],\n\n        [[0.00392157, 0.00392157, 0.07843137],\n         [0.02352941, 0.01960784, 0.12156863],\n         [0.09411765, 0.39215686, 0.94901961],\n         ...,\n         [0.01568627, 0.02352941, 0.07058824],\n         [0.01176471, 0.01960784, 0.06666667],\n         [0.01176471, 0.01568627, 0.0745098 ]],\n\n        ...,\n\n        [[0.03529412, 0.02352941, 0.38039216],\n         [0.01960784, 0.01568627, 0.4       ],\n         [0.01568627, 0.02745098, 0.35686275],\n         ...,\n         [0.01960784, 0.03137255, 0.10196078],\n         [0.00784314, 0.03529412, 0.09803922],\n         [0.00784314, 0.03921569, 0.10588235]],\n\n        [[0.01568627, 0.01568627, 0.38039216],\n         [0.01176471, 0.02352941, 0.27843137],\n         [0.01960784, 0.02745098, 0.21568627],\n         ...,\n         [0.01176471, 0.04313725, 0.10980392],\n         [0.01176471, 0.03921569, 0.10196078],\n         [0.01176471, 0.04705882, 0.10196078]],\n\n        [[0.01176471, 0.03921569, 0.1372549 ],\n         [0.01176471, 0.03921569, 0.14901961],\n         [0.01176471, 0.03921569, 0.1372549 ],\n         ...,\n         [0.00784314, 0.03921569, 0.10588235],\n         [0.01176471, 0.03921569, 0.09411765],\n         [0.01176471, 0.04705882, 0.10196078]]],\n\n\n       [[[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 0.99607843],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]],\n\n        ...,\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ]]],\n\n\n       [[[0.13333333, 0.18431373, 0.19215686],\n         [0.17647059, 0.23921569, 0.25098039],\n         [0.27843137, 0.34901961, 0.38823529],\n         ...,\n         [0.10980392, 0.11372549, 0.09803922],\n         [0.08627451, 0.09411765, 0.07058824],\n         [0.07843137, 0.08627451, 0.0627451 ]],\n\n        [[0.35686275, 0.42352941, 0.48627451],\n         [0.45098039, 0.52941176, 0.60784314],\n         [0.5254902 , 0.58431373, 0.68627451],\n         ...,\n         [0.11764706, 0.12156863, 0.10980392],\n         [0.08235294, 0.08627451, 0.07058824],\n         [0.08235294, 0.08627451, 0.07058824]],\n\n        [[0.54901961, 0.60392157, 0.71764706],\n         [0.57254902, 0.64313725, 0.76078431],\n         [0.55686275, 0.65098039, 0.76862745],\n         ...,\n         [0.11372549, 0.11764706, 0.10980392],\n         [0.08235294, 0.08627451, 0.0745098 ],\n         [0.08627451, 0.09019608, 0.0745098 ]],\n\n        ...,\n\n        [[0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         [0.        , 0.        , 0.        ],\n         ...,\n         [0.03529412, 0.05098039, 0.04313725],\n         [0.03921569, 0.05098039, 0.04313725],\n         [0.03921569, 0.05882353, 0.05490196]],\n\n        [[0.        , 0.        , 0.        ],\n         [0.00392157, 0.00392157, 0.00392157],\n         [0.00392157, 0.00392157, 0.00392157],\n         ...,\n         [0.05098039, 0.06666667, 0.05882353],\n         [0.03921569, 0.04705882, 0.03921569],\n         [0.03921569, 0.05882353, 0.05098039]],\n\n        [[0.00784314, 0.00784314, 0.00784314],\n         [0.00784314, 0.00784314, 0.00784314],\n         [0.01176471, 0.01176471, 0.01176471],\n         ...,\n         [0.03529412, 0.05490196, 0.04705882],\n         [0.03921569, 0.05098039, 0.03921569],\n         [0.05098039, 0.07058824, 0.0627451 ]]]]), [1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1], None)"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=3, validation_split=0.3)\n"
   ]
  }
 ]
}